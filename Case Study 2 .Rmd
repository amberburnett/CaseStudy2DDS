---
title: "Case Study 2"
author: "Amber Burnett"
date: "8/18/2019"
output: html_document
---




```{r youtubevideolink,echo=TRUE}
# https://youtu.be/Nldr8kX4YsM
```

```{r INTRODUCTION, echo=TRUE}
# DDSAnalytics is an analytics company that specializes in talent management solutions for Fortune 100 companies. Talent management is defined as the iterative process of developing and retaining employees. It may include workforce planning, employee training programs, identifying high-potential employees and reducing/preventing voluntary employee turnover (attrition). To gain a competitive edge over its competition, DDSAnalytics is planning to leverage data science for talent management. The executive leadership has identified predicting employee turnover as its first application of data science for talent management. My company hasthey  tasked my data science team to conduct an analysis of existing employee data for Frito-Lay.
# So, Hello Ms. Frito and Mr. Lay!  I am Amber Burnett, a data scientist for data analyticsdds.  My contact information is included here for your convenience.  
Thank you for allowing me to be here today to report my attrition analysis on your company.  I noticed your company prides itself on the phrase “Our associates are more than just members of our team.  They are part of our family.” 
With that being said,  from our family at DDS Analytics to yours at Frito Lay, we are here to support you by keeping members of this family together for years to come.  So, How might I help with your turnover here at Frito-Lay?
First lets dig into the data…
```

```{r ATTRITION, echo=TRUE}
# Project 2: Attrition Model
case <- read.csv("~/Desktop/CaseStudy2-data.csv")
test.noatt <- read.csv("~/Desktop/CaseStudy2CompSet No Attrition.csv")

# I kept the following variables in the whole training data.
fof <- case[ , c(2:4, 7, 12, 15, 18, 22, 24, 27, 29, 30:36)]
fof$Turnover <- ifelse(fof$Attrition == "Yes", 1, 0)
fof$Freq.Travel <- ifelse(fof$BusinessTravel == "Travel_Frequently", 1, 0)
fof$Over.Time <- ifelse(fof$OverTime == "Yes", 1, 0)
# drop variables that are string 2,3,9
fo <- fof[ , c(1, 4:8, 10:21)]

# I kept the same variables in the whole testing data.
fos <- test.noatt[ , c(2:3, 6, 11, 14, 17, 21, 23, 26, 28, 29:35)]
fos$Freq.Travel <- ifelse(fos$BusinessTravel == "Travel_Frequently", 1, 0)
fos$Over.Time <- ifelse(fos$OverTime == "Yes", 1, 0)
# drop variables that are string 2,8
ft <- fos[ , c(1, 3:7, 9:19)]


#############################################################
# I split the whole training data into 2 subsets: one training data: train and one testing data: test.
# I tested the accuracy of the model.
 
split = 0.6 
smp_size <- floor(split * nrow(fo))

set.seed(123)
train_ind <- sample(seq_len(nrow(fo)), size = smp_size)

train <- fo[train_ind, ]
test <- fo[-train_ind, ]

#############################################################

library(e1071)
library(caret)

# KNN model 

# Method 1
# column 16 is the variable Turnover
# k=25 has the optimized sensitivity and specificity

results = class::knn(train[ , c(1:15, 17:18)], test[,c(1:15, 17:18)], train$Turnover, k=25)

# Accuracy for the testing data (subset of the big data of case study 2)
test$Turnover.Pred = results
confusionMatrix(table(test$Turnover, test$Turnover.Pred))


results2 = class::knn(fo[ , c(1:15, 17:18)], ft[,c(1:17)], fo$Turnover, k=25)

# Here I got the Predicted attrition using KNN regression for the validation dataset without actual attrition
ft$Turnover.Pred = results2

# I exported data with predicted attrition.
write.table(ft, "~/Desktop/Case2PredictionsBurnett knn Attrition.csv", sep=",", row.names=F)

#############################################################
# logistic model to compare with knn

library(ISLR)

glm.fit <- glm(Turnover ~ Freq.Travel + Over.Time + Age + DistanceFromHome+ EnvironmentSatisfaction + JobInvolvement + JobSatisfaction + NumCompaniesWorked + RelationshipSatisfaction + StockOptionLevel + TotalWorkingYears + WorkLifeBalance + YearsSinceLastPromotion, data = train, family = binomial)
summary(glm.fit)
turnover.prob.tr = predict(glm.fit, train, type="response")

glm.fit <- glm(Turnover ~ Freq.Travel + Over.Time + Age + DistanceFromHome+ EnvironmentSatisfaction + JobInvolvement + JobSatisfaction + NumCompaniesWorked + RelationshipSatisfaction + StockOptionLevel + TotalWorkingYears + WorkLifeBalance + YearsSinceLastPromotion, data = test, family = binomial)
turnover.prob.te = predict(glm.fit, test, type="response")

# I tested th3e accuracy of the training data -subset of the whole training data (casestudy2data).
train$turnover.pred = rep(0, dim(train)[1])
train$turnover.pred[ turnover.prob.tr > .2] = 1
table(train$turnover.pred, train$Turnover)
confusionMatrix(table(train$turnover.pred, train$Turnover))

# I tested the accuracy of the testing data -subset of the whole training data (casestudy2data).
test$pred = rep(0, dim(test)[1])
test$pred[ turnover.prob.te > .2] = 1
table(test$pred, test$Turnover)
confusionMatrix(table(test$pred, test$Turnover))

# Success rate of my prediction = 1 -error rate

mean(train$turnover.pred==train$Turnover)


# I got the predicted attrition using Logistic regression for the validation dataset without actual attrition.
glm.fit <- glm(Turnover ~ Freq.Travel + Over.Time + Age + DistanceFromHome+ EnvironmentSatisfaction + JobInvolvement + JobSatisfaction + NumCompaniesWorked + RelationshipSatisfaction + StockOptionLevel + TotalWorkingYears + WorkLifeBalance + YearsSinceLastPromotion, data = fo, family = binomial)
turnover.prob.test = predict(glm.fit, ft, type="response")

ft$Attrition.Pred = rep(0, dim(ft)[1])
ft$Attrition.Pred[ turnover.prob.test > .2] = 1

# I exported the data with predicted attrition.
write.table(ft, "~/Desktop/Case2PredictionsBurnett Attrition.csv", sep=",", row.names=F)


#############################################################
```




``````{r SALARY, echo=TRUE}
# Project 2: Salary Model
test.salary <- read.csv("~/Desktop/CaseStudy2CompSet No Salary.csv")
case$Freq.Travel <- ifelse(case$BusinessTravel == "Travel_Frequently", 1, 0)
test.salary$Freq.Travel <- ifelse(test.salary$BusinessTravel == "Travel_Frequently", 1, 0)


#############################################################
# I split the whole training data into 2 subsets: one training data: train and one testing data: test.
# I tested the accuracy of the model.
 
split = 0.6 
smp_size <- floor(split * nrow(case))

set.seed(123)
train_ind <- sample(seq_len(nrow(case)), size = smp_size)

train <- case[train_ind, ]
test <- case[-train_ind, ]

#############################################################
# I used the Linear Model to predict monthly income.


mod <- lm(MonthlyIncome ~ Freq.Travel + TotalWorkingYears + DistanceFromHome + JobLevel + YearsWithCurrManager + JobRole + TotalWorkingYears*JobRole, data=train)
print(summary(mod))

MSalary.Pred <- predict(mod, test)

# I got the accuracy of the model using testing data: as a subset of the training data (casestudy2 data).
ASE_lm <- mean((test$MonthlyIncome-MSalary.Pred)^2)
RMSE <- sqrt(ASE_lm)
RMSE

# I got the accuracy of the model using the whole training data (casestudy2 data).
MSalary.Predall <- predict(mod, case)
ASE_lm_all <- mean((case$MonthlyIncome-MSalary.Predall)^2)
RMSE_all <- sqrt(ASE_lm_all)
RMSE_all

# I got the Predicted monthly salary using linear regression for the validation dataset without actual salary.

mod.all <- lm(MonthlyIncome ~ Freq.Travel + TotalWorkingYears + DistanceFromHome + JobLevel + YearsWithCurrManager + JobRole + TotalWorkingYears*JobRole, data=case)
print(summary(mod.all))

test.salary$Salary.Pred <- predict(mod.all, test.salary)

# I exported the  data with predicted salary.
write.table(test.salary, "~/Desktop/Case2PredictionsBurnett Salary.csv", sep=",", row.names=F)

#############################################################
```


```{r Plots,echo=TRUE}
library(corrplot)
# slide 2-This is a correlation plot looking at factorws that correlate to attrition.
correlations <- cor(fo[,c(4,5,8,9,16:18)])
corrplot(correlations, method="circle")
#slide 3-This plot identifies key factor 1: overtime.  
ggplot(fof, aes(TotalWorkingYears, Turnover, color=OverTime)) + stat_smooth(method="glm", formula=y~x, alpha=0.2, size=2, aes(fill=OverTime)) + geom_point(position=position_jitter(height=0.01, width=0)) + xlab("TotalWorkingYears") + ylab("Pr(Turnover)")
#slide 4-This plot identifies key factor 2:job involvement.
case$Turnover <- ifelse(fof$Attrition == "Yes", 1, 0)
ggplot(case, aes(JobInvolvement, Turnover, color=JobRole)) + stat_smooth(method="glm", formula=y~x, alpha=0.2, size=2, aes(fill=JobRole)) + geom_point(position=position_jitter(height=0.01, width=0)) + xlab("JobInvolvement") + ylab("Pr(Turnover)")
#slide 5-This plot identifies key factor 3:job satisfaction.
ggplot(case, aes(JobSatisfaction, Turnover, color=JobRole)) + stat_smooth(method="glm", formula=y~x, alpha=0.2, size=2, aes(fill=JobRole)) + geom_point(position=position_jitter(height=0.01, width=0)) + xlab("JobSatisfaction") + ylab("Pr(Turnover)")
```

```{r CONCLUSION, echo=TRUE}
Using different methods and models, I have concluded three factors signficantly affect Frito-Lay's attrition and turnover.  I have made recommendations and provided you with a custom salary model as a guideline to help keep employees with Frito_Lay.
```
















```
